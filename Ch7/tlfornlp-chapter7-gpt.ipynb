{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Preliminaries\nWrite requirements to file, anytime you run it, in case you have to go back and recover dependencies.\n\nRequirements are hosted for each notebook in the companion github repo, and can be pulled down and installed here if needed. Companion github repo is located at https://github.com/azunre/transfer-learning-for-nlp"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip freeze > kaggle_image_requirements.txt","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Open Ended Text Generation with GPT-2"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Pipeline uses `gpt2` by default, but we specify it explicitly to be fully transparent\nfrom transformers import pipeline\ngpt = pipeline('text-generation',model='gpt2')","execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cb791f5769d4c4895ccadd3fa159f31"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73a3ef56c9a7454683c5a42e0b6cc66e"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"997f89a8e6444f2490be1d50d276a0d6"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02aee87dc267412a8b00e1964b09b1a7"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cf048ecfa814d0ea2743ebd834dbed3"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Now, let's generate some text with GPT-2"},{"metadata":{"trusted":true},"cell_type":"code","source":"gpt(\"Transfer learning is a field of study\", max_length=100)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"[{'generated_text': 'Transfer learning is a field of study for both young professionals and adults.\\n\\nCognitive Training and Training\\n\\nIt is one of the most rewarding professions with a strong community of young professionals. The curriculum emphasizes learning the ability to work in groups. Participants are presented with options ranging from computer games in which you can try on different classes (computer games with graphics elements, computer games with character designs, board games and other types of games), to computer games and computer games with language, music, or'}]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"A nonexhaustive list of other model choices suitable for text generation within the transformers library include \"ctrl\" (CTRL - huge! too big for Kaggle), \"xlnet-base-cased\" (XLNet), \"transfo-xl-wt103\" (Transformer XL)... These often need to be padded very carefully to work well, GPT-2 is the safest choice for open-ended text generation. See https://huggingface.co/transformers/usage.html#text-generation for more."},{"metadata":{},"cell_type":"markdown","source":"# Conversational Text Generation with DialoGPT\n\nDialoGPT is an extension of GPT to conversational response generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import AutoModelWithLMHead, AutoTokenizer # you can use these utility classes that automatically load the right classes\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer # or these more specific classes directly\nimport torch\n\ntokenizer = GPT2Tokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\nmodel = GPT2LMHeadModel.from_pretrained(\"microsoft/DialoGPT-medium\")","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"687dadde650b4d569c5aaa8785cc0469"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2785fff2097149c690d5e9a40a37b180"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa7e445e1451424092e8371b41d94a4e"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=862955157.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f6a97736d9046ddb54a207a85e21624"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chat for 5 Lines\nconversation_length = 5\nfor step in range(conversation_length):\n    # encode new user input, add end-of-sentence token, return tensor\n    new_user_inputs_ids = tokenizer.encode(input(\"User: \") + tokenizer.eos_token, return_tensors='pt')\n    \n    # add new input to chat history\n    bot_input_ids = torch.cat([chat_history_ids, new_user_inputs_ids], dim=1) if step > 0 else new_user_inputs_ids\n    \n    # generate a response of up to max_length tokens\n    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n    \n    # display response\n    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"User: hi robot\nDialoGPT: Hello, human.\nUser: huh?\nDialoGPT: I'm a bot.\nUser: ok, what is your name?\nDialoGPT: Robot. I'm a robot.\nUser: Alright then...\nDialoGPT: Robot. I'm a robot.\nUser: Say something else?\nDialoGPT: Robot. I'm a robot.\n"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}