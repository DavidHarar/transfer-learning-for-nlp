{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "First install critical dependencies not already on the Kaggle docker imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.4\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\r\n",
      "\u001b[K     |████████████████████████████████| 317kB 2.9MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.1.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (5.1.2)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (2.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.16.4)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.12.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.2.1)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.0.8)\r\n",
      "Installing collected packages: keras\r\n",
      "  Found existing installation: Keras 2.3.0\r\n",
      "    Uninstalling Keras-2.3.0:\r\n",
      "      Successfully uninstalled Keras-2.3.0\r\n",
      "Successfully installed keras-2.2.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4 # critical dependency\n",
    "!pip install -q bert-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write requirements to file, anytime you run it, in case you have to go back and recover dependencies.\n",
    "\n",
    "Latest known such requirements are hosted for each notebook in the companion github repo, and can be pulled down and installed here if needed. Companion github repo is located at https://github.com/azunre/transfer-learning-for-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > kaggle_image_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neural network libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other key imports\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tokenization, Stop-word and Punctuation Removal Functions\n",
    "\n",
    "Before proceeding, we must decide how many samples to draw from each class. We must also decide the maximum number of tokens per email, and the maximum length of each token. This is done by setting the following overarching hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for bert model and tokenization\n",
    "Nsamp = 1000 # number of samples to generate in each class - 'spam', 'not spam'\n",
    "maxtokens = 200 # the maximum number of tokens per document\n",
    "maxtokenlen = 100 # the maximum length of each token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    if row is None or row is '':\n",
    "        tokens = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            tokens = row.split(\" \")[:maxtokens]\n",
    "        except:\n",
    "            tokens=\"\"\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use regular expressions to remove unnecessary characters**\n",
    "\n",
    "Next, we define a function to remove punctuation marks and other nonword characters (using regular expressions) from the emails with the help of the ubiquitous python regex library. In the same step, we truncate all tokens to hyperparameter maxtokenlen defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_expressions(row):\n",
    "    tokens = []\n",
    "    try:\n",
    "        for token in row:\n",
    "            token = token.lower()\n",
    "            token = re.sub(r'[\\W\\d]', \"\", token)\n",
    "            token = token[:maxtokenlen] # truncate token\n",
    "            tokens.append(token)\n",
    "    except:\n",
    "        token = \"\"\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop-word removal**\n",
    "\n",
    "Let’s define a function to remove stopwords - words that occur so frequently in language that they offer no useful information for classification. This includes words such as “the” and “are”, and the popular library NLTK provides a heavily-used list that will employ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')    \n",
    "\n",
    "# print(stopwords) # see default stopwords\n",
    "# it may be beneficial to drop negation words from the removal list, as they can change the positive/negative meaning\n",
    "# of a sentence - but we didn't find it to make a difference for this problem\n",
    "# stopwords.remove(\"no\")\n",
    "# stopwords.remove(\"nor\")\n",
    "# stopwords.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word_removal(row):\n",
    "    token = [token for token in row if token not in stopwords]\n",
    "    token = filter(None, token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Assemble IMDB Review Dataset\n",
    "\n",
    "Download the labeled IMDB reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "!tar xzf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "# function for shuffling data\n",
    "def unison_shuffle(data, header):\n",
    "    p = np.random.permutation(len(header))\n",
    "    data = data[p]\n",
    "    header = np.asarray(header)[p]\n",
    "    return data, header\n",
    "\n",
    "def load_data(path):\n",
    "    data, sentiments = [], []\n",
    "    for folder, sentiment in (('neg', 0), ('pos', 1)):\n",
    "        folder = os.path.join(path, folder)\n",
    "        for name in os.listdir(folder):\n",
    "            with open(os.path.join(folder, name), 'r') as reader:\n",
    "                  text = reader.read()\n",
    "            text = tokenize(text)\n",
    "            text = stop_word_removal(text)\n",
    "            text = reg_expressions(text)\n",
    "            data.append(text)\n",
    "            sentiments.append(sentiment)\n",
    "    data_np = np.array(data)\n",
    "    data, sentiments = unison_shuffle(data_np, sentiments)\n",
    "    \n",
    "    return data, sentiments\n",
    "\n",
    "train_path = os.path.join('aclImdb', 'train')\n",
    "test_path = os.path.join('aclImdb', 'test')\n",
    "raw_data, raw_header = load_data(train_path)\n",
    "\n",
    "print(raw_data.shape)\n",
    "print(len(raw_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::data_train::\n",
      "[list(['at', 'beginning', 'movie', 'beautiful', 'photography', 'scenes', 'fox', 'amazing', 'however', 'story', 'slow', 'boring', 'and', 'little', 'girl', 'begins', 'domesticate', 'fox', 'leads', 'tragic', 'events', 'we', 'live', 'forest', 'frequently', 'see', 'foxes', 'one', 'thing', 'anyone', 'know', 'leave', 'wild', 'animals', 'wild', 'enjoy', 'afar', 'this', 'movie', 'sets', 'terrible', 'example', 'children', 'watching', 'it', 'trying', 'make', 'wild', 'creature', 'pet', 'i', 'know', 'point', 'story', 'supposed', 'be', 'even', 'terrible', 'events', 'main', 'fox', 'little', 'girl', 'still', 'wanting', 'play', 'kits', 'does', 'never', 'learn', 'lesson', 'and', 'scenes', 'featuring', 'predator', 'animals', 'fox', 'adds', 'trauma', 'inflicted', 'children', 'watching', 'movie', 'what', 'disappointment', 'movie', 'was', 'and', 'horrible', 'story', 'tells', 'the', 'final', 'narrated', 'dialog', 'stupid', 'time', 'wife', 'i', 'screaming', 'tv', 'i', 'absolutely', 'hated', 'movie', 'would', 'never', 'recommend', 'anyone'])\n",
      " list(['jean', 'rollin', 'artistic', 'nonsense', 'vampires', 'aliens', 'quest', 'immortalitybr', 'br', 'the', 'women', 'beautiful', 'photography', 'stunning', 'the', 'dialog', 'inane', 'its', 'laughable', 'mess', 'great', 'look', 'semblance', 'horror', 'film', 'thriller', 'purely', 'awful', 'im', 'trying', 'figure', 'were', 'suppose', 'scared', 'not', 'at', 'time', 'put', 'not', 'its', 'odd', 'mix', 'art', 'film', 'horror', 'never', 'quite', 'meshes', 'nice', 'look', 'never', 'seems', 'mean', 'anything', 'means', 'scary', 'even', 'occasional', 'shot', 'sequence', 'creates', 'moment', 'frisson', 'its', 'well', 'made', 'pretentious', 'twaddle', 'something', 'leave', 'background', 'living', 'wall', 'paper', 'like', 'naked', 'women'])\n",
      " list(['when', 'people', 'ask', 'i', 'like', 'movies', 'much', 'i', 'usually', 'respond', 'have', 'seen', 'artgallery', 'sequence', 'de', 'palmas', 'dressed', 'kill', 'that', 'scene', 'alone', 'pretty', 'much', 'represents', 'everything', 'i', 'want', 'see', 'film', 'if', 'i', 'film', 'director', 'would', 'kind', 'thing', 'id', 'like', 'do', 'pure', 'cinema', 'one', 'way', 'describing', 'sequence', 'truly', 'amazing', 'see', 'director', 'de', 'palmas', 'entire', 'movie', 'works', 'high', 'artistic', 'frequency', 'scene', 'it', 'dreamlike', 'movie', 'clever', 'hell', 'zest', 'intelligence', 'dozen', 'films', 'put', 'together', 'i', 'think', 'movie', 'raises', 'important', 'point', 'always', 'topic', 'heated', 'discussion', 'could', 'movie', 'rely', 'solely', 'technique', 'still', 'considered', 'artistic', 'success', 'the', 'film', 'message', 'speak', 'of', 'acting', 'great', 'service', 'style', 'script', 'short', 'logic', 'de', 'palmas', 'movie', 'makes', 'really', 'good', 'case', 'style', 'handled', 'properly', 'sustain', 'feature', 'length', 'film', 'sure', 'michael', 'caine', 'angie', 'dickinson', 'nancy', 'allen', 'keith', 'gordon', 'give', 'superlative', 'performances'])\n",
      " ...\n",
      " list(['one', 'would', 'think', 'film', 'young', 'persons', 'coming', 'terms', 'burgeoning', 'homosexuality', 'would', 'anything', 'boring', 'think', 'again', 'this', 'production', 'bottled', 'sold', 'cure', 'insomnia', 'ten', 'times', 'potent', 'sleep', 'aid', 'market', 'its', 'almost', 'film', 'maker', 'considered', 'making', 'movie', 'got', 'lazy', 'decided', 'instead', 'run', 'series', 'random', 'and', 'randomly', 'boring', 'images', 'gonowhere', 'scenes', 'throw', 'couple', 'actual', 'scenes', 'featuring', 'actual', 'acting', 'pretend', 'good', 'lighting', 'inst', 'important', 'filmmaking', 'process', 'wrap', 'auspices', 'arthouse', 'film', 'this', 'exactly', 'kind', 'crappy', 'product', 'makes', 'easy', 'lot', 'traditional', 'filmmakers', 'poopoo', 'indie', 'film', 'movement', 'keeps', 'general', 'public', 'easily', 'embracing', 'indie', 'filmsbr', 'br', 'if', 'interested', 'films', 'covering', 'subject', 'matter', 'much', 'better', 'tuning', 'great', 'short', 'films', 'available', 'logos', 'website', 'renting', 'get', 'real', 'better', 'yet', 'read', 'stone', 'butch', 'blues', 'whatever', 'do', 'skip', 'longwinded', 'piece', 'dreck'])\n",
      " list(['american', 'movies', 'war', 'nazis', 'simply', 'cannot', 'good', 'they', 'refrain', 'becoming', 'idiot', 'following', 'agenda', 'all', 'nazis', 'bad', 'crazy', 'proud', 'americans', 'modest', 'yet', 'capable', 'sensible', 'human', 'come', 'on', 'stop', 'bullshit', 'the', 'main', 'character', 'says', 'something', 'like', 'by', 'trial', 'make', 'aggressive', 'war', 'crime', 'is', 'america', 'peaceful', 'nation', 'world', '', '', 'billion', 'defense', 'budget', '', 'china', 'b', 'is', 'simply', 'spent', 'without', 'any', 'roi', 'why', 'portray', 'america', 'peaceful', 'nation', 'isnt', 'i', 'deeply', 'dislike', 'movies', 'agenda', '', 'throw', 'art', 'hell', 'try', 'persuade', 'us', 'believing', 'something', 'hollywood', 'put', 'label', 'movies', 'record', 'companies', 'parental', 'advisory', 'label', 'we', 'bullshit', 'advisory', 'propaganda', 'advisory', 'politically', 'correct', 'advisory', 'label', 'movies', 'this', 'one', 'them'])\n",
      " list(['phil', 'alien', 'one', 'quirky', 'films', 'humour', 'based', 'around', 'oddness', 'everything', 'rather', 'actual', 'punchlinesbr', 'br', 'at', 'first', 'odd', 'pretty', 'funny', 'movie', 'progressed', 'i', 'find', 'jokes', 'oddness', 'funny', 'anymorebr', 'br', 'its', 'low', 'budget', 'film', 'thats', 'never', 'problem', 'itself', 'pretty', 'interesting', 'characters', 'eventually', 'i', 'lost', 'interestbr', 'br', 'i', 'imagine', 'film', 'would', 'appeal', 'stoner', 'currently', 'partakingbr', 'br', 'for', 'something', 'similar', 'better', 'try', 'brother', 'another', 'planet'])]\n"
     ]
    }
   ],
   "source": [
    "# Subsample required number of samples\n",
    "random_indices = np.random.choice(range(len(raw_header)),size=(Nsamp*2,),replace=False)\n",
    "data_train = raw_data[random_indices]\n",
    "header = raw_header[random_indices]\n",
    "\n",
    "print(\"DEBUG::data_train::\")\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display sentiments and their frequencies in the dataset, to ensure it is roughly balanced between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiments and their frequencies:\n",
      "[0 1]\n",
      "[1004  996]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(header, return_counts=True)\n",
    "print(\"Sentiments and their frequencies:\")\n",
    "print(unique_elements)\n",
    "print(counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x/train_y list details, to make sure it is of the right form:\n",
      "1400\n",
      "[['what night perry mason have gun will travel followed gunsmoke when half hour finally pm came sea hunt wonderful opening theme music mikes boat sailing new adventure terrific regardless story lead character played lloyd bridges strong honest sincere a mans man boys man this brought interest boats lasted years why show cable make available video idea too bad']\n",
      " ['while bad gametomovie adaptations hunk crud fare much betterbr br boll seems pathological inability accept make good movies one days hell run money stop inflicting world bombsbr br the acting subpar dialog sounded like reading teleprompters bolls special little touches seen throughout whole thingbr br like uwe boll movies one existbr br plain simplebr br just like uwe boll exist _']\n",
      " ['youre using imdbbr br youve given hefty votes favourite filmsbr br its something enjoy doingbr br and this fifty seconds one world ends another beginsbr br how given ten i wonder give seven eight exactly could the first film ever made better for record long still opening shot great showmanship superb innovation perfectly suited situation and dog bike lovely touch all within fifty secondsbr br the word genius often overusedbr br this genius']\n",
      " ...\n",
      " ['standard rise fame tale high points number one lonette mckee sister gives stunning star making performance the fact never became huge sensation beyond me sadly supporting character forced focus irena carters bland character sparkle whose rise fame easy boring unconvincing however whenever girls go stage perform movie comes back life the original music curis mayfield must praised the copy i saw old vhs tape the picture quality pretty low well production values im guessing all all worth gander']\n",
      " ['youd think serious sightseeing premise movie takes place primarily two characters travel  miles france saudi arabia going europe  italy bulgaria croatia slovenia turkey arriving middle east but tour stopovers soaking sightsbr br redas father twilight years wishes haj however since walking taking mule question chooses travel mecca car he cant drive therefore enlists help reda sons protest get broken vehiclebr br but reda see point go along dad could opt plane he resents idea put personal life hold pilgrimage understand and hence set arduous journey father son best palsbr br the beauty movie witness development father son pair challenges face']\n",
      " ['a memorable line short lived show after viewing episode line introduced fraternity intramural flag football team started using line break huddles offense instead ready  break quarter back said football rest squad responded you bet a fun way break huddle opponents scratching heads watched show using line added unique element season ill never forget we best season time college year small way due fun using line the show pretty much stinker lives memories  pi kappa phi intramural flag football squad west virginia tech']]\n",
      "[1 0 1 0 0]\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# function for converting data into the right format, due to the difference in required format from sklearn models\n",
    "# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\n",
    "def convert_data(raw_data,header):\n",
    "    converted_data, labels = [], []\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        # combine list of tokens representing each email into single string\n",
    "        out = ' '.join(raw_data[i])\n",
    "        converted_data.append(out)\n",
    "        labels.append(header[i])\n",
    "    converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\n",
    "    \n",
    "    return converted_data, np.array(labels)\n",
    "\n",
    "data_train, header = unison_shuffle(data_train, header)\n",
    "\n",
    "# split into independent 70% training and 30% testing sets\n",
    "idx = int(0.7*data_train.shape[0])\n",
    "# 70% of data for training\n",
    "train_x, train_y = convert_data(data_train[:idx],header[:idx])\n",
    "# remaining 30% for testing\n",
    "test_x, test_y = convert_data(data_train[idx:],header[idx:])\n",
    "\n",
    "print(\"train_x/train_y list details, to make sure it is of the right form:\")\n",
    "print(len(train_x))\n",
    "print(train_x)\n",
    "print(train_y[:5])\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, Train and Evaluate BERT Model\n",
    "First define critical functions that define various components of the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def create_tokenizer_from_hub_module(bert_path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module = hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [tokenization_info[\"vocab_file\"], tokenization_info[\"do_lower_case\"]]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a custom tf hub BERT layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"mean\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the custom TF hub BERT embedding layer within a higher-level function to define the overall model. More specifically, we put a dense trainable layer of output dimension 256 on top of the BERT embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build overall model\n",
    "def build_model(max_seq_length):\n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    # just extract BERT features, don't fine-tune\n",
    "    bert_output = BertLayer(n_fine_tune_layers=0)(bert_inputs)\n",
    "    # train dense classification layer on top of extracted features\n",
    "    dense = tf.keras.layers.Dense(256, activation=\"relu\")(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to initialize variables correctly\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting examples to features: 100%|██████████| 1400/1400 [00:05<00:00, 279.17it/s]\n",
      "Converting examples to features: 100%|██████████| 600/600 [00:02<00:00, 278.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method BertLayer.call of <__main__.BertLayer object at 0x7faeb039d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertLayer.call of <__main__.BertLayer object at 0x7faeb039d710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      bert_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 197,121\n",
      "Non-trainable params: 110,104,890\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "1400/1400 [==============================] - 18s 13ms/sample - loss: 0.6032 - acc: 0.6743 - val_loss: 0.5442 - val_acc: 0.7183\n",
      "Epoch 2/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.4746 - acc: 0.7736 - val_loss: 0.4647 - val_acc: 0.8100\n",
      "Epoch 3/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.4246 - acc: 0.8114 - val_loss: 0.4551 - val_acc: 0.7967\n",
      "Epoch 4/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.4045 - acc: 0.8193 - val_loss: 0.4723 - val_acc: 0.7783\n",
      "Epoch 5/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.3816 - acc: 0.8300 - val_loss: 0.4346 - val_acc: 0.8100\n"
     ]
    }
   ],
   "source": [
    "# tf hub bert model path\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\" \n",
    "\n",
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(bert_path)\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_x, train_y)\n",
    "test_examples = convert_text_to_examples(test_x, test_y)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids,train_input_masks,train_segment_ids,train_labels) = \\\n",
    "convert_examples_to_features(tokenizer, train_examples, max_seq_length=maxtokens)\n",
    "(test_input_ids,test_input_masks,test_segment_ids,test_labels) = \\\n",
    "convert_examples_to_features(tokenizer, test_examples, max_seq_length=maxtokens)\n",
    "\n",
    "# Build model\n",
    "model = build_model(maxtokens)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "# Train model\n",
    "history = model.fit([train_input_ids, train_input_masks, train_segment_ids],train_labels,\n",
    "                    validation_data=([test_input_ids, test_input_masks, test_segment_ids],test_labels),\n",
    "                    epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Convergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_history = pd.DataFrame(history.history)\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot(range(df_history.shape[0]),df_history['val_acc'],'bs--',label='validation')\n",
    "plt.plot(range(df_history.shape[0]),df_history['acc'],'r^--',label='training')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('BERT Email Classification Training')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('BERTConvergence.eps', format='eps')\n",
    "fig.savefig('BERTConvergence.pdf', format='pdf')\n",
    "fig.savefig('BERTConvergence.png', format='png')\n",
    "fig.savefig('BERTConvergence.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make figures downloadable to local system in interactive mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=BERTConvergence.svg>Download file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "def create_download_link(title = \"Download file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(filename='BERTConvergence.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTConvergence.eps  BERTConvergence.svg  aclImdb_v1.tar.gz\r\n",
      "BERTConvergence.pdf  __notebook__.ipynb   kaggle_image_requirements.txt\r\n",
      "BERTConvergence.png  aclImdb\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!rm -rf aclImdb\n",
    "!rm aclImdb_v1.tar.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
