{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING\n",
    "**Please make sure to \"COPY AND EDIT NOTEBOOK\" to use compatible library dependencies! DO NOT CREATE A NEW NOTEBOOK AND COPY+PASTE THE CODE - this will use latest Kaggle dependencies at the time you do that, and the code will need to be modified to make it work. Also make sure internet connectivity is enabled on your notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "First install critical dependencies not already on the Kaggle docker image. **NOTE THAT THIS NOTEBOOK USES TENSORFLOW 1.14 IN ORDER TO BE COMPARED WITH ELMo, WHICH WAS NOT PORTED TO TENSORFLOW 2.X. To see equivalent Tensorflow 2.X BERT Code, see https://www.kaggle.com/azunre/tlfornlp-chapters2-3-spam-bert-tf2** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.4\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\r\n",
      "\u001b[K     |████████████████████████████████| 317kB 866kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.2.1)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.16.4)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (5.1.2)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (2.9.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.12.0)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.0.8)\r\n",
      "Installing collected packages: keras\r\n",
      "  Found existing installation: Keras 2.3.0\r\n",
      "    Uninstalling Keras-2.3.0:\r\n",
      "      Successfully uninstalled Keras-2.3.0\r\n",
      "Successfully installed keras-2.2.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4 # critical dependency\n",
    "!pip install -q bert-tensorflow==1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write requirements to file, anytime you run it, in case you have to go back and recover Kaggle dependencies. **MOST OF THESE REQUIREMENTS WOULD NOT BE NECESSARY FOR LOCAL INSTALLATION**\n",
    "\n",
    "Requirements are hosted for each notebook in the companion github repo, and can be pulled down and installed here if needed. Companion github repo is located at https://github.com/azunre/transfer-learning-for-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > kaggle_image_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neural network libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other key imports\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tokenization, Stop-word and Punctuation Removal Functions\n",
    "Before proceeding, we must decide how many samples to draw from each class. We must also decide the maximum number of tokens per email, and the maximum length of each token. This is done by setting the following overarching hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for bert model and tokenization\n",
    "Nsamp = 1000 # number of samples to generate in each class - 'spam', 'not spam'\n",
    "maxtokens = 200 # the maximum number of tokens per document\n",
    "maxtokenlen = 100 # the maximum length of each token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    if row is None or row is '':\n",
    "        tokens = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            tokens = row.split(\" \")[:maxtokens]\n",
    "        except:\n",
    "            tokens=\"\"\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use regular expressions to remove unnecessary characters**\n",
    "\n",
    "Next, we define a function to remove punctuation marks and other nonword characters (using regular expressions) from the emails with the help of the ubiquitous python regex library. In the same step, we truncate all tokens to hyperparameter maxtokenlen defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_expressions(row):\n",
    "    tokens = []\n",
    "    try:\n",
    "        for token in row:\n",
    "            token = token.lower()\n",
    "            token = re.sub(r'[\\W\\d]', \"\", token)\n",
    "            token = token[:maxtokenlen] # truncate token\n",
    "            tokens.append(token)\n",
    "    except:\n",
    "        token = \"\"\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop-word removal**\n",
    "\n",
    "Let’s define a function to remove stopwords - words that occur so frequently in language that they offer no useful information for classification. This includes words such as “the” and “are”, and the popular library NLTK provides a heavily-used list that will employ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')    \n",
    "print(stopwords) # see default stopwords\n",
    "\n",
    "def stop_word_removal(row):\n",
    "    token = [token for token in row if token not in stopwords]\n",
    "    token = filter(None, token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Preprocess Enron dataset\n",
    "Read Enron dataset and get a sense for the data by printing sample messages to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 517401 rows and 2 columns!\n",
      "                       file                                            message\n",
      "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
      "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
      "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
      "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
      "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "filepath = \"../input/enron-email-dataset/emails.csv\"\n",
    "\n",
    "# Read the data into a pandas dataframe called emails\n",
    "emails = pd.read_csv(filepath)\n",
    "\n",
    "print(\"Successfully loaded {} rows and {} columns!\".format(emails.shape[0], emails.shape[1]))\n",
    "print(emails.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
      "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: tim.belden@enron.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Here is our forecast\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# take a closer look at the first email\n",
    "print(emails.loc[0][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    }
   ],
   "source": [
    "# Separate headers from the message bodies\n",
    "import email\n",
    "\n",
    "def extract_messages(df):\n",
    "    messages = []\n",
    "    for item in df[\"message\"]:\n",
    "        # Return a message object structure from a string\n",
    "        e = email.message_from_string(item)    \n",
    "        # get message body  \n",
    "        message_body = e.get_payload()\n",
    "        messages.append(message_body)\n",
    "    print(\"Successfully retrieved message body from e-mails!\")\n",
    "    return messages\n",
    "\n",
    "bodies = extract_messages(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Rick, thanks for seeing me individually on Friday. \\n\\nThere has not yet been any announcement for EBS. I welcome my new reporting \\nto Sue Nord, but I would like to see some kind of official note on the new \\nstructure. I would like to know what my budget for Europe is and what the new \\nproced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Goodbye Enron, Hello Dynegy.\\n\\nStay in touch.\\n\\nCharles\\n\\n-----Original Message-----\\nFrom: Mark.Taylor@enron.com [mailto:Mark.Taylor@enron.com]\\nSent: Friday, November 09, 2001 11:03 AM\\nTo: cfishkin@kpmg.com; Tana.Jones@enron.com\\nSubject: RE: note\\n\\n\\nThanks for your note.  We're hanging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\nCurrently the Northend temperatures show to drop from mid 30's Saturday to 19 degrees Sunday and 10 degrees for system weighted temperature for Monday and start back up into the high 20's and low 30's by Friday of next week. With these kind of temperatures and Redfield withdrawals falling of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Count me in.\\n---------------------- Forwarded by Kay Mann/Corp/Enron on 05/08/2001 11:32 \\nAM ---------------------------\\nFrom: Roseann Engeldorf/ENRON@enronXgate on 05/02/2001 02:20 PM\\nTo: Sheila Tweed/HOU/ECT@ECT, Kay Mann/Corp/Enron@Enron, Barbara N \\nGray/HOU/ECT@ECT, Dale Rasmussen/HOU/E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Your prompt attention to this matter is greatly appreciated....!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0  Rick, thanks for seeing me individually on Friday. \\n\\nThere has not yet been any announcement for EBS. I welcome my new reporting \\nto Sue Nord, but I would like to see some kind of official note on the new \\nstructure. I would like to know what my budget for Europe is and what the new \\nproced...\n",
       "1  Goodbye Enron, Hello Dynegy.\\n\\nStay in touch.\\n\\nCharles\\n\\n-----Original Message-----\\nFrom: Mark.Taylor@enron.com [mailto:Mark.Taylor@enron.com]\\nSent: Friday, November 09, 2001 11:03 AM\\nTo: cfishkin@kpmg.com; Tana.Jones@enron.com\\nSubject: RE: note\\n\\n\\nThanks for your note.  We're hanging ...\n",
       "2  \\n\\nCurrently the Northend temperatures show to drop from mid 30's Saturday to 19 degrees Sunday and 10 degrees for system weighted temperature for Monday and start back up into the high 20's and low 30's by Friday of next week. With these kind of temperatures and Redfield withdrawals falling of...\n",
       "3  Count me in.\\n---------------------- Forwarded by Kay Mann/Corp/Enron on 05/08/2001 11:32 \\nAM ---------------------------\\nFrom: Roseann Engeldorf/ENRON@enronXgate on 05/02/2001 02:20 PM\\nTo: Sheila Tweed/HOU/ECT@ECT, Kay Mann/Corp/Enron@Enron, Barbara N \\nGray/HOU/ECT@ECT, Dale Rasmussen/HOU/E...\n",
       "4                                                                                                                                                                                                                                             Your prompt attention to this matter is greatly appreciated....!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract random 10000 enron email bodies for building dataset\n",
    "import random\n",
    "bodies_df = pd.DataFrame(random.sample(bodies, 10000))\n",
    "\n",
    "# expand default pandas display options to make emails more clearly visible when printed\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "\n",
    "bodies_df.head() # you could do print(bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following (commented out) code is arguably the more \"pythonic\" way of achieving the extraction of bodies from messages. It is only 2 lines long and achieves the same result. However, we feel the code above is more transparent with regards to how the processing is carried out, and as such leave this here for the python experts if they prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages = emails[\"message\"].apply(email.message_from_string)\n",
    "#bodies_df = messages.apply(lambda x: x.get_payload()).sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Preprocess Fraudulent \"419\" Email Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 3978 spam emails!\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../input/fraudulent-email-corpus/fradulent_emails.txt\"\n",
    "with open(filepath, 'r',encoding=\"latin1\") as file:\n",
    "    data = file.read()\n",
    "    \n",
    "# split on a code word appearing close to the beginning of each email\n",
    "fraud_emails = data.split(\"From r\")\n",
    "\n",
    "print(\"Successfully loaded {} spam emails!\".format(len(fraud_emails)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0  FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-27-587908.\\nE-MAIL: (james_ngola2002@maktoob.com).\\n\\nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\n\\nDEAR FRIEND,\\n\\nI AM ( DR.) JAMES NGOLA, THE PERSONAL ASSISTANCE TO THE LATE CONGOLESE (PRESIDENT LAURENT KABILA) WHO WAS ASSASSINATED BY HIS BODY G...\n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom officer and work as Assistant controller of the Customs and Excise department Of the Federal Ministry of Internal Affairs stationed at the Murtala Mohammed International Airport, Ikeja, Lagos-Nigeria.\\n\\nAfter the sudden death of the former Head of s...\n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n",
       "3  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ELEME KINGDOM \\nCHIEF DANIEL ELEME, PHD, EZE 1 OF ELEME.E-MAIL \\nADDRESS:obong_715@epatra.com  \\n\\nATTENTION:PRESIDENT,CEO Sir/ Madam. \\n\\nThis letter might surprise you because we have met\\nneither in person nor by correspondence. But I believe\\nit is...\n",
       "4  Dear sir, \\n \\nIt is with a heart full of hope that I write to seek your help in respect of the context below. I am Mrs. Maryam Abacha the former first lady of the former Military Head of State of Nigeria General Sani Abacha whose sudden death occurred on 8th of June 1998 as a result of cardiac ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_bodies = extract_messages(pd.DataFrame(fraud_emails,columns=[\"message\"],dtype=str))\n",
    "fraud_bodies_df = pd.DataFrame(fraud_bodies[1:])\n",
    "\n",
    "fraud_bodies_df.head() # you could do print(fraud_bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting It All Together To Assemble Dataset\n",
    "\n",
    "Now, putting all the preprocessing steps together we assemble our dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Convert everything to lower-case, truncate to maxtokens and truncate each token to maxtokenlen\n",
    "EnronEmails = bodies_df.iloc[:,0].apply(tokenize)\n",
    "EnronEmails = EnronEmails.apply(stop_word_removal)\n",
    "EnronEmails = EnronEmails.apply(reg_expressions)\n",
    "EnronEmails = EnronEmails.sample(Nsamp)\n",
    "\n",
    "SpamEmails = fraud_bodies_df.iloc[:,0].apply(tokenize)\n",
    "SpamEmails = SpamEmails.apply(stop_word_removal)\n",
    "SpamEmails = SpamEmails.apply(reg_expressions)\n",
    "SpamEmails = SpamEmails.sample(Nsamp)\n",
    "\n",
    "raw_data = pd.concat([SpamEmails,EnronEmails], axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined data represented as numpy array is:\n",
      "(2000,)\n",
      "Data represented as numpy array is:\n",
      "[list(['dear', 'madamsiri', 'greet', 'name', 'godi', 'mrs', 'rebecca', 'atkins', 'south', 'africai', 'married', 'late', 'mr', 'smith', 'atkins', 'ofblessed', 'memory', 'oil', 'explorer', 'inkuwait', 'brunei', 'fifteen', 'years', 'beforehe', 'died', 'year', 'we', 'married', 'twelve', 'years', 'without', 'achild', 'he', 'died', 'brief', 'illness', 'thatlasted', 'four', 'days', 'before', 'deathwe', 'devoted', 'god', 'respectother', 'serve', 'himsince', 'death', 'i', 'battling', 'withboth', 'cancer', 'fibroid', 'problems', 'when', 'latehusband', 'alive', 'deposited', 'sum', 'ofmillion', 'eighteen', 'million', 'five', 'hundredthousand', 'us', 'dollars', 'deposit', 'companyin', 'europethe', 'money', 'deposited', 'familyvaluablestreasure', 'security', 'reasonsrecently', 'doctor', 'told', 'i', 'sixmonths', 'live', 'due', 'cancer', 'problem', 'thislead', 'stroke', 'attack', 'bother', 'thoughbecause', 'i', 'cannot', 'move', 'i', 'use', 'tohaving', 'known', 'condition', 'i', 'decided', 'entrust', 'thisfund', 'either', 'philanthropic', 'organization', 'ordevoted', 'individual', 'utilize', 'moneythe', 'way', 'i', 'going', 'instructs', 'herein', 'theusmillion', 'goes', 'ensure', 'areprepared', 'task', 'ahead', '', 'money', 'willbe', 'used', 'sincerity'])\n",
      " list(['attention', 'permit', 'inform', 'desire', 'going', 'business', 'relationship', 'you', 'i', 'got', 'contact', 'information', 'countrys', 'informationdirectory', 'desperate', 'search', 'someone', 'assist', 'mesecretly', 'confidentially', 'relocating', 'managing', 'funds', 'i', 'prayed', 'selected', 'name', 'among', 'names', 'due', 'esteeming', 'nature', 'trustworthy', 'person', 'i', 'business', '', 'i', 'must', 'hesitate', 'confine', 'simple', 'sincere', 'businessi', 'mrs', 'hilda', 'p', 'tomson', 'legal', 'wife', 'chief', 'securityofficer', 'late', 'major', 'tomson', 'page', 'my', 'husband', 'former', 'headof', 'presidential', 'guard', 'mr', 'charles', 'taylor', 'liberia', 'presidentbefore', 'death', 'husband', 'may', 'th', 'attemptby', 'rebels', 'life', 'president', 'ctaylor', 'brutally', 'injured', 'subsequently', 'rushed', 'presidential', 'hospital', 'monrovia', 'later', 'diedbefore', 'deathhe', 'secretly', 'called', 'bedside', 'told', 'sum', 'usmillion', 'dollars', 'seventeen', 'million', 'dollarswhich', 'deposited', 'name', 'legal', 'wife', 'beneficiary', 'next', 'kin', 'depositing', 'fund'])\n",
      " list(['from', 'george', 'amachreegeneral', 'manager', 'financenigeria', 'lng', 'limitedc', '', 'c', 'towersplot', '', 'sanusi', 'fafunwa', 'streetvictoria', 'islandp', 'm', 'b', '', 'marina', 'lagosnigeriawwwnlngcomre', 'transfer', 'of', 'usdtwenty', 'million', 'five', 'hundred', 'thousand', 'united', 'states', 'dollars', 'only', 'to', 'a', 'safe', 'accountsirit', 'warmest', 'pleasure', 'writing', 'confidential', 'business', 'offer', 'irrespective', 'factthat', 'met', 'done', 'thing', 'reimpose', 'absolute', 'confidence', 'nevertheless', 'adage', 'says', 'day', 'begins', 'story', 'line', 'strong', 'perspective', 'i', 'determined', 'to', 'communicate', 'much', 'conviction', 'give', 'proposal', 'a', 'second', 'thought', 'considerationas', 'earlier', 'stated', 'i', 'mr', 'daniel', 'amachree', 'general', 'manager', 'finance', 'working', 'nigeria', 'liquefied', 'natural', 'gas', 'nlng', 'my', 'agency', 'produce', 'export', 'nlg', 'ngl', 'safely', 'reliably', 'profitable', 'grow', 'business', 'full', 'potential', 'helping', 'put', 'flares', 'nigeria', 'and', 'virtue', 'unique', 'position', 'office', 'general', 'manager', 'finance', 'i', 'elevated', 'commission', 'become', 'chairman', 'foreign', 'contract', 'tender', 'board', 'committee', 'whose', 'responsibility', 'award', 'supervise', 'foreign', 'contract', 'ensure', 'executed', 'promptlyconsequently', 'i', 'chairman'])\n",
      " ...\n",
      " list(['', 'forwarded', 'daren', 'j', 'farmerhouect', '', '', 'am', 'jamie', 'lynnenron', '', 'pmto', 'mark', 'warnerhouectect', 'toby', 'kuehletsenronenron', 'sean', 'sargentcorpenronenron', 'teresa', 'wrighthrcorpenronenron', 'kevin', 'm', 'prestohouectect', 'micardo', 'johnscorpenronenron', 'greg', 'pipercorpenronenron', 'allan', 'weatherfordgcoenronenron', 'brad', 'morsehouectect', 'rafael', 'rizopatronlonectect', 'gary', 'w', 'lamphierhouectect', 'daren', 'j', 'farmerhouectect', 'perron', 'rogershouectect', 'ryan', 'smithaacorpenronenron', 'archie', 'n', 'eubanksenron_developmentenron_development', 'mike', 'd', 'smithhoueesees', 'fred', 'rhodesaacorpenronenron', 'chris', 'barnesenrongateway', 'eric', 'bensonetsenronenron', 'charles', 'caineecfenronenron', 'mike', 'croucherhouectect', 'clarence', 'davisecfenronenron', 'john', 'garrettcorpenronenron', 'willie', 'haggertyecfenronenron', 'eric', 'j', 'hardyhouectect', 'dwight', 'jameshouectect', 'kevin', 'kuykendallhouectect', 'richard', 'a', 'lammersenron_developmentenron_development', 'john', 'meeksetsenronenron', 'richard', 'orellanacorpenronenron', 'john', 'meeksetsenronenron', 'fimber', 'phillipecfenronenron', 'ruben', 'salinasecfenronenron', 'john', 'shupakhouectectcc', 'subject', 'spring', 'basketball', 'tournament', 'forwarded', 'jamie', 'lynnetsenron', '', '', 'pm', 'jamie', 'lynn', '', 'pmto', 'oliver', 'brownenron_developmentenron_development', 'martin', 'rosettaenron_developmentenron_development', 'pam', 'newsomeenron_developmentenron_development', 'ryan', 'woodsenron_developmentenron_development', 'mike', 'layneenron_developmentenron_development', 'fred', 'salinasenron_developmentenron_development', 'sean', 'longenron_developmentenron_development', 'kevin', 'ruffcornenron_developmentenron_development', 'keith', 'sparksenron_developmentenron_development', 'aaron', 'mackeyenron_developmentenron_development', 'braedi', 'craigenron', 'communicationsenron', 'communications', 'jennifer', 'mcclainenron', 'communicationsenron', 'communications', 'john', 'garrettcorpenronenron', 'darrell', 'schoolcraftetsenronenron', 'stanley', 'hortoncorpenronenron', 'pamela', 'carteretsenronenron', 'brandon', 'whittakerenron_developmentenron_development', 'chris', 'williamsenrongateway', 'johnny', 'mitchelletsenronenron', 'mike', 'bryantotsenronenron', 'rick', 'buyhouectect', 'bjorn', 'hagelmannhouectect', 'tom', 'moranhouectect', 'patrick', 'hickeyenron', 'communicationsenron', 'communications', 'brant', 'reveshouectect', 'samantha', 't', 'davidsonhouectect', 'tangie', 'dykesetsenronenron', 'tara', 'e', 'turkhouectect', 'dan', 'leffhoueesees', 'mark', 'pratoriushoueesees', 'brad', 'pedenhoueesees', 'david', 'blankenshipcorpenronenron', 'milton', 'brownhrcorpenronenron', 'ken', 'reeveshouectect', 'rory', 'junemancorpenronenron', 'fred', 'bridgewaterenron_developmentenron_development', 'sandy', 'robertscorpenronenron', 'derek', 'andersonhouectect', 'david', 'odellhrcorpenronenroncc', 'bcc', 'jamie', 'lynnetsenronsubject', 'spring', 'basketball', 'tournamentenron', 'is'])\n",
      " list(['i', 'forwarded', 'copy', 'fernleys', 'announcement', 'regarding', 'new', 'role', 'forglobal', 'products', 'trading', 'support', 'your', 'discussions', 'houston', 'last', 'week', 'musthave', 'swayed', 'accept', 'challenges', 'there', 'congratulations', 'onyour', 'new', 'role', 'as', 'step', 'new', 'position', 'please', 'let', 'know', 'ican', 'best', 'support', 'role', 'global', 'risk', 'management', 'operations', 'i', 'amforwarding', 'copy', 'announcement', 'regarding', 'expanded', 'role', 'wassent', 'january', 'assuming', 'paying', 'particular', 'attentionto', 'trading', 'operations', 'issues', 'point', 'time', 'may', 'one', 'thoseemail', 'messages', 'skipped', 'i', 'thought', 'might', 'helpful', 'youto', 'understand', 'focus', 'i', 'working', 'trading', 'operationsgroups', 'around', 'globe', 'i', 'certainly', 'look', 'forward', 'working', 'youtim', 'kevin', 'i', 'understand', 'kevin', 'move', 'role', 'focused', 'fulltime', 'onsystems', 'implementation', 'who', 'assume', 'daytoday', 'lead', 'responsibilityfor', 'global', 'products', 'trading', 'operations', 'houston', 'thatindividual', 'report', 'you', 'i', 'london', 'office', 'week', 'march', '', 'i', 'leavehouston'])\n",
      " list(['would', 'guys', 'see', 'flowing', 'current', 'day', 'points', 'please', 'forwarded', 'chris', 'germanyhouect', '', '', 'pm', 'alleman', 'alden', 'allemanaldenepenergycom', '', '', 'pmto', 'cc', 'subject', 'high', 'btu', 'level', 'on', 'the', 'larosa', 'lateraljanuary', '', '', '', 'pm', 'cctto', 'all', 'tennessee', 'customersre', 'high', 'btu', 'level', 'on', 'the', 'larosa', 'lateraltennessee', 'encountering', 'high', 'btu', 'levels', 'larosa', 'lateral', 'these', 'highbtulevels', 'subject', 'customer', 'complaints', 'delivered', 'gasis', 'interfering', 'proper', 'operation', 'various', 'lines', 'regulatorsmeters', 'appliances', 'located', 'larosa', 'lateral', 'beginning', 'thejanuary', '', 'gas', 'day', 'tennessee', 'requests', 'point', 'operators', 'receipt', 'meterslocated', 'larosa', 'lateral', 'tender', 'tennessee', 'gas', 'meets', 'gasquality', 'specifications', 'found', 'general', 'terms', 'conditions', 'thetennessee', 'gas', 'tariffthe', 'following', 'list', 'receipt', 'meters', 'located', 'larosa', 'lateral', 'mustang', 'island', 'dehyd', 'redfish', 'bay', 'dehyd', 'stedman', 'island', 'dehyd', 'ingleside', 'dehyd', 'mustang', 'island', '', 'red', 'fish', 'bay', 'transport', 'mustang', 'islandabsent', 'resolution', 'problems', 'beginning', 'january', '', 'gas', 'daytennessee', 'accept', 'nominations', 'meters', 'larosa', 'lateraltendering', 'specification'])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of combined data represented as numpy array is:\")\n",
    "print(raw_data.shape)\n",
    "print(\"Data represented as numpy array is:\")\n",
    "print(raw_data)\n",
    "\n",
    "# corresponding labels\n",
    "Categories = ['spam','notspam']\n",
    "header = ([1]*Nsamp)\n",
    "header.extend(([0]*Nsamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x/train_y list details, to make sure it is of the right form:\n",
      "1400\n",
      "[['image image american express gold card events dear louise american express gold card events offers prime tickets nations hottest entertainment events exclusive benefit american express gold card platinum card centurion card corporate centurion card corporate platinum card executive corporate card small business members for select cardmembers like you american express making access prime tickets easier ever you receive regular email updates notifying you upcoming events cases shows announced to general public if wish receive email updates please see instructions bottom email look for this weeks highlights proof in new haven to view new events image link complete listing gold card events already sale please select a city image atlanta image select florida cities image image phoenix image boston image houston image st louis image charlotte image los angeles image washington dc image chicago']\n",
      " ['set wpatti thompson x']\n",
      " ['not plane boat train ill call  pm cdt original messagefrom steffes james d senttuesday october    pmtokeene patricksubjectre intervention nevada power rate caseshow pm friday afternoon you planejim original messagefrom keene patrick senttuesday october    pmtosteffes james dsubjectre intervention nevada power rate casesim nm thur fri always available phone got time mind original messagefrom steffes james d senttuesday october    pmtokeene patricksubjectre intervention nevada power rate casespat if friday lets sit thanksjim original messagefrom keene patrick senttuesday october    pmtobonnie drinkwater bdrinkwatermcdonaldcaranocomenron kaufman paulccsteffes james dsubjectre intervention nevada power rate caseswe intervene based potential interest serving customers pursuant abshort answerpauls language it possible may want reduce revenue requirements recommending use financial products minimize utility revenue risk we intervened ab  regulation proceeding enron energy services inc enron power marketing inc if think raise issues outside unbundling limit']\n",
      " ...\n",
      " ['roger presented comments transwetern permits which issued klagetoh luepp compressor station the critical sensitive issue us item  below the permits really restrict us cause us major operational concerns held  ppmvd nox co throughout entire operating range turbines we would really appreciate help assistance issue let know additional information may need the responsible official name change danny pribble vp southwestoperationsthe draft permit limits nox co emissions  ppmv  o basedon hour average except periods startup shutdown at fand ge data indicates rates achievable alloperating conditions however ge data indicates nox co may high  ppmv lowload conditions  lowerthe permit application represented turbine operations base load  ofthe time reduced load operations  loadoccurring of time twp also included  safety factor cover periods ofreduced operating loads']\n",
      " ['done  mail woman']\n",
      " ['oml sa  nd floor building grayston drive sandton joburgsouth africadear i mrsmith anderso head audit department african developemnet banksouth africa and reasons become obvious read on i obtained address particulars internet address listing please exercise patience read message i urgent confidential business proposition you on june th  crude oil contractor kuwait national petroleum corporation engr ahmed youseff mustafa  national kuwait made numbered time  fixed deposit  calendar months value musd thirty six million united states dollars onlyin branch on maturity sent a routine notification forwarding address got reply after month sent reminder finally contract employers the kuwait national petroleum corporation wrote inform us engr a y mustafa died automobile accident died without making a will attempts trace next kin kuwait embassy fruitless i therefore made investigations discovered mr mustafa actively opposed government country kuwait']]\n",
      "[0 0 0 1 1]\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# function for shuffling data in unison with labels/header\n",
    "def unison_shuffle(a, b):\n",
    "    p = np.random.permutation(len(b))\n",
    "    data = a[p]\n",
    "    header = np.asarray(b)[p]\n",
    "    return data, header\n",
    "\n",
    "# function for converting data into the right format, due to the difference in required format from sklearn models\n",
    "# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\n",
    "def convert_data(raw_data,header):\n",
    "    converted_data, labels = [], []\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        out = ' '.join(raw_data[i])\n",
    "        converted_data.append(out)\n",
    "        labels.append(header[i])\n",
    "        #print(i)\n",
    "    converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\n",
    "    \n",
    "    return converted_data, np.array(labels)\n",
    "\n",
    "raw_data, header = unison_shuffle(raw_data, header)\n",
    "\n",
    "# split into independent 70% training and 30% testing sets\n",
    "idx = int(0.7*raw_data.shape[0])\n",
    "# 70% of data for training\n",
    "train_x, train_y = convert_data(raw_data[:idx],header[:idx])\n",
    "# remaining 30% for testing\n",
    "test_x, test_y = convert_data(raw_data[idx:],header[idx:])\n",
    "\n",
    "print(\"train_x/train_y list details, to make sure it is of the right form:\")\n",
    "print(len(train_x))\n",
    "print(train_x)\n",
    "print(train_y[:5])\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 70% of 2000 is 1400, looks good! (for Nsamp=1000)\n",
    "\n",
    "Onwards!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, Train and Evaluate BERT Model\n",
    "First define critical functions that define various components of the BERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def create_tokenizer_from_hub_module(bert_path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module = hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [tokenization_info[\"vocab_file\"], tokenization_info[\"do_lower_case\"]]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a custom tf hub BERT layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"mean\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the custom TF hub BERT embedding layer within a higher-level function to define the overall model. More specifically, we put a dense trainable layer of output dimension 256 on top of the BERT embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build overall model\n",
    "def build_model(max_seq_length):\n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    # just extract BERT features, don't fine-tune\n",
    "    bert_output = BertLayer(n_fine_tune_layers=0)(bert_inputs)\n",
    "    # train dense classification layer on top of extracted features\n",
    "    dense = tf.keras.layers.Dense(256, activation=\"relu\")(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to initialize variables correctly\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting examples to features: 100%|██████████| 1400/1400 [00:04<00:00, 285.24it/s]\n",
      "Converting examples to features: 100%|██████████| 600/600 [00:01<00:00, 319.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method BertLayer.call of <__main__.BertLayer object at 0x7f6f8511a588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertLayer.call of <__main__.BertLayer object at 0x7f6f8511a588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      bert_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 197,121\n",
      "Non-trainable params: 110,104,890\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "1400/1400 [==============================] - 18s 13ms/sample - loss: 0.2032 - acc: 0.9336 - val_loss: 0.0565 - val_acc: 0.9883\n",
      "Epoch 2/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.0550 - acc: 0.9843 - val_loss: 0.0386 - val_acc: 0.9867\n",
      "Epoch 3/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.0318 - acc: 0.9929 - val_loss: 0.0282 - val_acc: 0.9917\n",
      "Epoch 4/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.0247 - acc: 0.9943 - val_loss: 0.0518 - val_acc: 0.9817\n",
      "Epoch 5/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.0224 - acc: 0.9950 - val_loss: 0.0353 - val_acc: 0.9883\n"
     ]
    }
   ],
   "source": [
    "# tf hub bert model path\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\" \n",
    "\n",
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(bert_path)\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_x, train_y)\n",
    "test_examples = convert_text_to_examples(test_x, test_y)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids,train_input_masks,train_segment_ids,train_labels) = \\\n",
    "convert_examples_to_features(tokenizer, train_examples, max_seq_length=maxtokens)\n",
    "(test_input_ids,test_input_masks,test_segment_ids,test_labels) = \\\n",
    "convert_examples_to_features(tokenizer, test_examples, max_seq_length=maxtokens)\n",
    "\n",
    "# Build model\n",
    "model = build_model(maxtokens)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "# Train model\n",
    "history = model.fit([train_input_ids, train_input_masks, train_segment_ids],train_labels,\n",
    "                    validation_data=([test_input_ids, test_input_masks, test_segment_ids],test_labels),\n",
    "                    epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Convergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_history = pd.DataFrame(history.history)\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot(range(df_history.shape[0]),df_history['val_acc'],'bs--',label='validation')\n",
    "plt.plot(range(df_history.shape[0]),df_history['acc'],'r^--',label='training')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('BERT Email Classification Training')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('BERTConvergence.eps', format='eps')\n",
    "fig.savefig('BERTConvergence.pdf', format='pdf')\n",
    "fig.savefig('BERTConvergence.png', format='png')\n",
    "fig.savefig('BERTConvergence.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make figures downloadable to local system in interactive mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=BERTConvergence.svg>Download file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "def create_download_link(title = \"Download file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(filename='BERTConvergence.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
