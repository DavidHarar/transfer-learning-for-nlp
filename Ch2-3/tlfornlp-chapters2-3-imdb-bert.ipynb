{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "First install critical dependencies not already on the Kaggle docker imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.4\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\r\n",
      "\u001b[K     |████████████████████████████████| 317kB 882kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.12.0)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.0.8)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.16.4)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (5.1.2)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (2.9.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras==2.2.4) (1.2.1)\r\n",
      "Installing collected packages: keras\r\n",
      "  Found existing installation: Keras 2.3.0\r\n",
      "    Uninstalling Keras-2.3.0:\r\n",
      "      Successfully uninstalled Keras-2.3.0\r\n",
      "Successfully installed keras-2.2.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4 # critical dependency\n",
    "!pip install -q bert-tensorflow==1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write requirements to file, anytime you run it, in case you have to go back and recover dependencies.\n",
    "\n",
    "Latest known such requirements are hosted for each notebook in the companion github repo, and can be pulled down and installed here if needed. Companion github repo is located at https://github.com/azunre/transfer-learning-for-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > kaggle_image_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neural network libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other key imports\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tokenization, Stop-word and Punctuation Removal Functions\n",
    "\n",
    "Before proceeding, we must decide how many samples to draw from each class. We must also decide the maximum number of tokens per email, and the maximum length of each token. This is done by setting the following overarching hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for bert model and tokenization\n",
    "Nsamp = 1000 # number of samples to generate in each class - 'spam', 'not spam'\n",
    "maxtokens = 200 # the maximum number of tokens per document\n",
    "maxtokenlen = 100 # the maximum length of each token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    if row is None or row is '':\n",
    "        tokens = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            tokens = row.split(\" \")[:maxtokens]\n",
    "        except:\n",
    "            tokens=\"\"\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use regular expressions to remove unnecessary characters**\n",
    "\n",
    "Next, we define a function to remove punctuation marks and other nonword characters (using regular expressions) from the emails with the help of the ubiquitous python regex library. In the same step, we truncate all tokens to hyperparameter maxtokenlen defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_expressions(row):\n",
    "    tokens = []\n",
    "    try:\n",
    "        for token in row:\n",
    "            token = token.lower()\n",
    "            token = re.sub(r'[\\W\\d]', \"\", token)\n",
    "            token = token[:maxtokenlen] # truncate token\n",
    "            tokens.append(token)\n",
    "    except:\n",
    "        token = \"\"\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop-word removal**\n",
    "\n",
    "Let’s define a function to remove stopwords - words that occur so frequently in language that they offer no useful information for classification. This includes words such as “the” and “are”, and the popular library NLTK provides a heavily-used list that will employ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')    \n",
    "\n",
    "# print(stopwords) # see default stopwords\n",
    "# it may be beneficial to drop negation words from the removal list, as they can change the positive/negative meaning\n",
    "# of a sentence - but we didn't find it to make a difference for this problem\n",
    "# stopwords.remove(\"no\")\n",
    "# stopwords.remove(\"nor\")\n",
    "# stopwords.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word_removal(row):\n",
    "    token = [token for token in row if token not in stopwords]\n",
    "    token = filter(None, token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Assemble IMDB Review Dataset\n",
    "\n",
    "Download the labeled IMDB reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "!tar xzf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "# function for shuffling data\n",
    "def unison_shuffle(data, header):\n",
    "    p = np.random.permutation(len(header))\n",
    "    data = data[p]\n",
    "    header = np.asarray(header)[p]\n",
    "    return data, header\n",
    "\n",
    "def load_data(path):\n",
    "    data, sentiments = [], []\n",
    "    for folder, sentiment in (('neg', 0), ('pos', 1)):\n",
    "        folder = os.path.join(path, folder)\n",
    "        for name in os.listdir(folder):\n",
    "            with open(os.path.join(folder, name), 'r') as reader:\n",
    "                  text = reader.read()\n",
    "            text = tokenize(text)\n",
    "            text = stop_word_removal(text)\n",
    "            text = reg_expressions(text)\n",
    "            data.append(text)\n",
    "            sentiments.append(sentiment)\n",
    "    data_np = np.array(data)\n",
    "    data, sentiments = unison_shuffle(data_np, sentiments)\n",
    "    \n",
    "    return data, sentiments\n",
    "\n",
    "train_path = os.path.join('aclImdb', 'train')\n",
    "test_path = os.path.join('aclImdb', 'test')\n",
    "raw_data, raw_header = load_data(train_path)\n",
    "\n",
    "print(raw_data.shape)\n",
    "print(len(raw_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::data_train::\n",
      "[list(['the', 'grudge', 'remake', 'shimizus', 'series', 'popular', 'japanese', 'horror', 'films', 'shimizu', 'knows', 'dealing', 'anything', 'new', 'intelligent', 'person', 'would', 'done', 'place', 'forgets', 'logic', 'concentrates', 'giving', 'viewers', 'fun', 'ride', 'he', 'uses', 'commonly', 'known', 'clichés', 'associated', 'ghost', 'stories', 'shimizu', 'plays', 'elements', 'imaginative', 'manner', 'the', 'nonlinear', 'narrative', 'mere', 'gimmick', 'interesting', 'way', 'present', 'sequences', 'different', 'perspectives', 'at', 'end', 'i', 'say', 'purpose', 'horror', 'film', 'scare', 'audience', 'the', 'way', 'comedy', 'make', 'people', 'laugh', 'movie', 'succeeded', 'flying', 'colors', 'i', 'watched', 'theater', 'audience', 'fun', 'see', 'viewers', 'go', 'wild', 'one', 'it', 'probably', 'play', 'well', 'living', 'room'])\n",
      " list(['i', 'saw', 'free', 'thankfully', 'wish', 'better', 'was', 'really', 'old', 'stuff', 'movie', 'studios', 'seem', 'foist', 'us', 'last', 'ten', 'yearsbr', 'br', 'ben', 'stiller', 'jennifer', 'anniston', 'play', 'couple', 'opposites', 'yet', 'attracted', 'otherbr', 'br', 'if', 'plot', 'line', 'take', 'surprise', 'thrill', 'you', 'movie', 'eitherbr', 'br', 'lots', 'sight', 'gags', 'fart', 'jokes', 'halfway', 'movie', 'i', 'began', 'realize', 'ben', 'stiller', 'really', 'funny', 'tries', 'very', 'hard', 'and', 'jennifer', 'anniston', 'really', 'pretty', 'hair', 'looks', 'great', 'and', 'hank', 'azaria', 'phillip', 'seymore', 'hoffman', 'must', 'got', 'paid', 'great', 'deal', 'money', 'kind', 'average', 'hohum', 'movie', 'ive', 'come', 'expect', 'thembr', 'br', 'what', 'interesting', 'i', 'saw', 'i', 'saw', 'american', 'splendor', 'truly', 'funny', 'original', 'movie', 'i', 'compared', 'two', 'head', 'found', 'wishing', 'movie', 'executives', 'would', 'forced', 'sit', 'two', 'movies', 'back', 'back', 'perhaps', 'would', 'knock', 'sense'])\n",
      " list(['the', 'first', 'one', 'meant', 'victory', 'this', 'one', 'means', 'defeat', 'it', 'takes', 'place', 'bolivia', 'guerillas', 'sick', 'wary', 'meet', 'much', 'sympathy', 'farmers', 'if', 'know', 's', 'history', 'understand', 'ends', 'you', 'understand', 'even', 'without', 'knowledgebr', 'br', 'del', 'toro', 'splendid', 'he', 'goes', 'building', 'icon', 'revolutionary', 'remains', 'same', 'regardless', 'success', 'failure', 'thats', 'guevara', 'according', 'legend', 'still', 'well', 'actedbr', 'br', 'the', 'documentary', 'feeling', 'around', 'icon', 'one', 'greatest', 'achievements', 'big', 'soderbergh', 'project', 'he', 'succeeded'])\n",
      " ...\n",
      " list(['i', 'loves', 'moviebecause', 'showed', 'killing', 'fun', 'save', 'ones', 'loved', 'heath', 'ledger', 'orlando', 'bloom', 'great', 'job', 'portraying', 'ned', 'joe', 'it', 'quick', 'inappropriate', 'scenes', 'right', 'that', 'the', 'language', 'mild', 'sometimes', 'even', 'know', 'there', 'this', 'movie', 'shows', 'outlaws', 'mean', 'vicious', 'killers', 'i', 'hope', 'people', 'watch', 'movie', 'learn', 'important', 'times', 'history', 'like', 'one', 'there', 'one', 'thing', 'fascinates', 'movie', 'got', 'inspiration', 'armor', 'book', 'ned', 'looked', 'at', 'also', 'people', 'remember', 'themfrom', 'armor', 'i', 'hope', 'people', 'watch', 'movie', 'get', 'interested', 'i', 'have'])\n",
      " list(['and', 'many', 'actors', 'get', 'stand', 'neurotic', 'compulsive', 'ubernew', 'yorker', 'persona', 'in', 'film', 'woody', 'played', 'will', 'ferrell', 'mercifully', 'less', 'direct', 'impersonation', 'one', 'kenneth', 'branagh', 'celebrity', 'its', 'annoyingly', 'repetitive', 'story', 'now', 'nebbishy', 'neurotic', 'man', 'wife', 'girlfriend', 'falls', 'madly', 'love', 'shiksa', 'queen', 'upon', 'projects', 'manner', 'perfection', 'everyone', 'lives', 'perfect', 'gigantic', 'apartments', 'great', 'manhattan', 'neighborhoods', 'everyone', 'constantly', 'patronizes', 'expensive', 'exclusive', 'restaurants', 'characters', 'relate', 'fascinating', 'anecdotes', 'discuss', 'arcane', 'philosophy', 'always', 'trip', 'hamptons', 'nebbishy', 'main', 'character', 'spazzes', 'sand', 'physical', 'exertion', 'possible', 'exposure', 'diseases', 'course', 'said', 'main', 'character', 'feels', 'guilty', 'lust', 'shiksa', 'queen', 'pursues', 'anyway', 'sometimes', 'succeeding', 'sometimes', 'failing', 'etcbr', 'br', 'this', 'tired', 'formula', 'proof', 'allen', 'really', 'great', 'film', 'artist', 'all', 'he', 'seems', 'like', 'dirty', 'old', 'man', 'libido', 'emotions', 'yearold', 'intent', 'upon', 'telling', 'boring', 'old', 'stories', 'again'])\n",
      " list(['i', 'excited', 'view', 'cataluñas', 'film', 'berlins', 'competition', 'but', 'presentation', 'i', 'total', 'disappointed', 'furious', 'too', 'much', 'blood', 'much', 'time', 'much', 'themes', 'nothing', 'the', 'spanish', 'civil', 'war', 'like', 'every', 'war', 'horrible', 'the', 'revenge', 'human', 'behavior', 'pretty', 'all', 'shown', 'uncountable', 'films', 'plays', 'well', 'relations', 'homosexuals', 'scepticism', 'spain', 'catholicism', '', 'but', 'mr', 'villaronga', 'try', 'pseudo', 'tragedy', 'belongs', 'worst', 'films', 'history', 'it', 'really', 'pity', 'see', 'angela', 'molina', 'movie', 'i', 'advise', 'nobody', 'circumstances', 'go', 'see', 'film'])]\n"
     ]
    }
   ],
   "source": [
    "# Subsample required number of samples\n",
    "random_indices = np.random.choice(range(len(raw_header)),size=(Nsamp*2,),replace=False)\n",
    "data_train = raw_data[random_indices]\n",
    "header = raw_header[random_indices]\n",
    "\n",
    "print(\"DEBUG::data_train::\")\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display sentiments and their frequencies in the dataset, to ensure it is roughly balanced between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiments and their frequencies:\n",
      "[0 1]\n",
      "[ 982 1018]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(header, return_counts=True)\n",
    "print(\"Sentiments and their frequencies:\")\n",
    "print(unique_elements)\n",
    "print(counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x/train_y list details, to make sure it is of the right form:\n",
      "1400\n",
      "[['sean know i think absolutely greatest actor world i cant commend this comedy strong suitbr br however fault some stuff hard understand alfred lynch decent job gotta wonder lines came beginningbr br once again sean i apologize']\n",
      " ['much made rohmers use digital technology fill in background at times works well scene grace maid witness afar kings execution particularly striking at times gives film strangely amateurish look resembling home video however major failing sheer artificiality mise en scene creates alienating effect viewer we know watching real feel characters to frank i care happened lady dukebr br the major failing i regret say performance lucy russell leading role she virtually every scene success otherwise film rests performance ok speaking foreign language incapable expressing real emotion her emoting scene recounts friend mme de meyler an excellent performance debutante helena dubiel seeing head pole caused embarrassed laughter audience also watch hands']\n",
      " ['was single positive film critics knew nothing video games could spot gaming errors made no damage taken damage clearly visible towards beginning primary examplebr br and i may missed something super mario bros  suppose game never played before well is case i miss anything fred savages character even girl know much game already were talking things people know second third playthroughbr br beyond factual gaming errors general low quality film itself nothing honestly memorable the kid even good playing video games footage showed a lot kids i knew way back days significantly experienced on top acting storyline mediocre strongest points the characters bland completely uninteresting wizard the youngest child silent completely dry child cliché little kid almost never talks']\n",
      " ...\n",
      " ['i glad able say almost positive things movie karas tasuiev sisters renaissancebr br and firstly looks ought look boys adventure renaissance tale cops investigation search missing young scientistilona tasuiev geneticist researcher avalon companybr br the tale karas ilona bislane is though much less known sin city better movie one appreciated connoisseurs to french comics aficionados even meaningful i enriched french comics collection last week though im uptodate the atmosphere music characters lines plot nice endearing a parisian top cop karas displayed find young woman rising star medicalgenetic research ilona tasuieva mildly hot blonde whose rebel sister bislane erotically preferable i guessbr br for me oldie aficionado comics tv series renaissance marvelously beautiful cartoon like replay wild wild west episodehere mythological past replaced equally mythological futuremore jaded blasé but']\n",
      " ['there movies native americans i especially think using actual real native americans would right thing i know archie belaney played pierce brosnan excellent job portraying character since englishman but suggestion hollywood put american indians roles never use anyone else the sioux nation put back burner far long their poverty disgrace country it firm belief country return black hills sioux we ask israel return lands arabs make effort same ashamed ourselves we must practice preach']\n",
      " ['wellmade basically dreary lowlife melodrama which according accompanying interview lead isabelle huppert writerdirector pialat infused good deal autobiographical detail given mainly unsympathetic characters involved compliments  seem troubled man huppert also says pialat often disappeared days end shoot br br the acting uniformly excellent however despite relatively young age huppert costar gerard depardieu as title character already forefront modern french stars  status which varying degrees success still hold daybr br i  pialats films vhs to watch pile albeit french without english subtitles due fact also loulous oppressive realism  spite undeniable artistic merit  i cant say im particular hurry check now']]\n",
      "[0 0 0 1 1]\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# function for converting data into the right format, due to the difference in required format from sklearn models\n",
    "# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\n",
    "def convert_data(raw_data,header):\n",
    "    converted_data, labels = [], []\n",
    "    for i in range(raw_data.shape[0]):\n",
    "        # combine list of tokens representing each email into single string\n",
    "        out = ' '.join(raw_data[i])\n",
    "        converted_data.append(out)\n",
    "        labels.append(header[i])\n",
    "    converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\n",
    "    \n",
    "    return converted_data, np.array(labels)\n",
    "\n",
    "data_train, header = unison_shuffle(data_train, header)\n",
    "\n",
    "# split into independent 70% training and 30% testing sets\n",
    "idx = int(0.7*data_train.shape[0])\n",
    "# 70% of data for training\n",
    "train_x, train_y = convert_data(data_train[:idx],header[:idx])\n",
    "# remaining 30% for testing\n",
    "test_x, test_y = convert_data(data_train[idx:],header[idx:])\n",
    "\n",
    "print(\"train_x/train_y list details, to make sure it is of the right form:\")\n",
    "print(len(train_x))\n",
    "print(train_x)\n",
    "print(train_y[:5])\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, Train and Evaluate BERT Model\n",
    "First define critical functions that define various components of the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def create_tokenizer_from_hub_module(bert_path):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module = hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [tokenization_info[\"vocab_file\"], tokenization_info[\"do_lower_case\"]]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a custom tf hub BERT layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"mean\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the custom TF hub BERT embedding layer within a higher-level function to define the overall model. More specifically, we put a dense trainable layer of output dimension 256 on top of the BERT embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build overall model\n",
    "def build_model(max_seq_length):\n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    # just extract BERT features, don't fine-tune\n",
    "    bert_output = BertLayer(n_fine_tune_layers=0)(bert_inputs)\n",
    "    # train dense classification layer on top of extracted features\n",
    "    dense = tf.keras.layers.Dense(256, activation=\"relu\")(bert_output)\n",
    "    pred = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dense)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to initialize variables correctly\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting examples to features: 100%|██████████| 1400/1400 [00:04<00:00, 331.15it/s]\n",
      "Converting examples to features: 100%|██████████| 600/600 [00:01<00:00, 336.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method BertLayer.call of <__main__.BertLayer object at 0x7fa5bfe039b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertLayer.call of <__main__.BertLayer object at 0x7fa5bfe039b0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      bert_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 197,121\n",
      "Non-trainable params: 110,104,890\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "1400/1400 [==============================] - 18s 13ms/sample - loss: 0.5651 - acc: 0.7021 - val_loss: 0.5333 - val_acc: 0.7150\n",
      "Epoch 2/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.4622 - acc: 0.7871 - val_loss: 0.4512 - val_acc: 0.8033\n",
      "Epoch 3/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.4109 - acc: 0.8179 - val_loss: 0.4330 - val_acc: 0.8083\n",
      "Epoch 4/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.4030 - acc: 0.8257 - val_loss: 0.5018 - val_acc: 0.7567\n",
      "Epoch 5/5\n",
      "1400/1400 [==============================] - 15s 11ms/sample - loss: 0.4047 - acc: 0.8200 - val_loss: 0.4191 - val_acc: 0.8050\n"
     ]
    }
   ],
   "source": [
    "# tf hub bert model path\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\" \n",
    "\n",
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(bert_path)\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_x, train_y)\n",
    "test_examples = convert_text_to_examples(test_x, test_y)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids,train_input_masks,train_segment_ids,train_labels) = \\\n",
    "convert_examples_to_features(tokenizer, train_examples, max_seq_length=maxtokens)\n",
    "(test_input_ids,test_input_masks,test_segment_ids,test_labels) = \\\n",
    "convert_examples_to_features(tokenizer, test_examples, max_seq_length=maxtokens)\n",
    "\n",
    "# Build model\n",
    "model = build_model(maxtokens)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "# Train model\n",
    "history = model.fit([train_input_ids, train_input_masks, train_segment_ids],train_labels,\n",
    "                    validation_data=([test_input_ids, test_input_masks, test_segment_ids],test_labels),\n",
    "                    epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Convergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_history = pd.DataFrame(history.history)\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot(range(df_history.shape[0]),df_history['val_acc'],'bs--',label='validation')\n",
    "plt.plot(range(df_history.shape[0]),df_history['acc'],'r^--',label='training')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('BERT Email Classification Training')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('BERTConvergence.eps', format='eps')\n",
    "fig.savefig('BERTConvergence.pdf', format='pdf')\n",
    "fig.savefig('BERTConvergence.png', format='png')\n",
    "fig.savefig('BERTConvergence.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make figures downloadable to local system in interactive mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=BERTConvergence.svg>Download file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "def create_download_link(title = \"Download file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(filename='BERTConvergence.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTConvergence.eps  BERTConvergence.svg  aclImdb_v1.tar.gz\r\n",
      "BERTConvergence.pdf  __notebook__.ipynb   kaggle_image_requirements.txt\r\n",
      "BERTConvergence.png  aclImdb\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!rm -rf aclImdb\n",
    "!rm aclImdb_v1.tar.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
